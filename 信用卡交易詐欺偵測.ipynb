{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52b92a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('fraudTrain.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99bdff83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1296675 entries, 0 to 1296674\n",
      "Data columns (total 23 columns):\n",
      " #   Column                 Non-Null Count    Dtype  \n",
      "---  ------                 --------------    -----  \n",
      " 0   Unnamed: 0             1296675 non-null  int64  \n",
      " 1   trans_date_trans_time  1296675 non-null  object \n",
      " 2   cc_num                 1296675 non-null  int64  \n",
      " 3   merchant               1296675 non-null  object \n",
      " 4   category               1296675 non-null  object \n",
      " 5   amt                    1296675 non-null  float64\n",
      " 6   first                  1296675 non-null  object \n",
      " 7   last                   1296675 non-null  object \n",
      " 8   gender                 1296675 non-null  object \n",
      " 9   street                 1296675 non-null  object \n",
      " 10  city                   1296675 non-null  object \n",
      " 11  state                  1296675 non-null  object \n",
      " 12  zip                    1296675 non-null  int64  \n",
      " 13  lat                    1296675 non-null  float64\n",
      " 14  long                   1296675 non-null  float64\n",
      " 15  city_pop               1296675 non-null  int64  \n",
      " 16  job                    1296675 non-null  object \n",
      " 17  dob                    1296675 non-null  object \n",
      " 18  trans_num              1296675 non-null  object \n",
      " 19  unix_time              1296675 non-null  int64  \n",
      " 20  merch_lat              1296675 non-null  float64\n",
      " 21  merch_long             1296675 non-null  float64\n",
      " 22  is_fraud               1296675 non-null  int64  \n",
      "dtypes: float64(5), int64(6), object(12)\n",
      "memory usage: 227.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb7b8b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['trans_date_trans_time'] = pd.to_datetime(df['trans_date_trans_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9292f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6731094594963818\n",
      "[0.68325288 0.67557252 0.66716924 0.67595819 0.66359447]\n",
      "0.5897967710829265\n",
      "[0.61292472 0.58960693 0.58960693 0.58161226 0.57523302]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "\n",
    "cat_cols=['category','gender']\n",
    "city_cols=['city']\n",
    "num_cols=['amt','unix_time']\n",
    "y_cols=['is_fraud']\n",
    "\n",
    "pre=ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num',Pipeline([\n",
    "            ('imputer',SimpleImputer(strategy='median')),\n",
    "        ]),num_cols),\n",
    "        ('cat',Pipeline([\n",
    "            ('imputer',SimpleImputer(strategy='most_frequent')),\n",
    "            ('ohe',OneHotEncoder()),\n",
    "        ]),cat_cols),\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "xgb=XGBClassifier(\n",
    "    n_estimators=200,        \n",
    "    max_depth=6,             \n",
    "    learning_rate=0.1,      \n",
    "    subsample=0.8,           \n",
    "    colsample_bytree=0.8,    \n",
    "    min_child_weight=5,      \n",
    "    reg_lambda=1.0,          \n",
    "    n_jobs=-1,              \n",
    "    random_state=42,\n",
    "    tree_method=\"hist\"  \n",
    ")\n",
    "\n",
    "pipe=Pipeline([\n",
    "    ('pre',pre),\n",
    "    ('xgb',xgb)\n",
    "])\n",
    "\n",
    "X=df.copy()\n",
    "y=df[y_cols[0]]\n",
    "\n",
    "cv=StratifiedKFold(n_splits=5,shuffle=True,random_state=42)\n",
    "scores_f1=cross_val_score(pipe,X,y,scoring='f1',cv=cv,n_jobs=-1)\n",
    "\n",
    "scores_recall=cross_val_score(pipe,X,y,scoring='recall',cv=cv,n_jobs=-1)\n",
    "\n",
    "\n",
    "print(scores_f1.mean())\n",
    "print(scores_f1)\n",
    "print(scores_recall.mean())\n",
    "print(scores_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1488d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6460434986902688 [0.63126593 0.65048924 0.66505246 0.63432562 0.64908425]\n",
      "0.5528626648862438 [0.54273192 0.56072874 0.57461646 0.53075031 0.55548589]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "groups = df['cc_num'].values\n",
    "\n",
    "gcv = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "scores_f1 = cross_val_score(pipe, X, y, groups=groups, scoring='f1', cv=gcv, n_jobs=-1)\n",
    "scores_recall = cross_val_score(pipe, X, y, groups=groups, scoring='recall', cv=gcv, n_jobs=-1)\n",
    "\n",
    "print(scores_f1.mean(), scores_f1)\n",
    "print(scores_recall.mean(), scores_recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45f4987a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_fraud\n",
      "0    0.994211\n",
      "1    0.005789\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df['is_fraud'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57b457d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PR-AUC: 0.7242123239693096 [0.70285883 0.72345375 0.73410921 0.72669426 0.73394557]\n",
      "ROC-AUC: 0.9939748027246378 [0.99391673 0.99343074 0.9940852  0.99454076 0.99390058]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    scale_pos_weight=171,   # 設定權重\n",
    "    eval_metric='aucpr',    # 改用 PR-AUC\n",
    "    tree_method='hist',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "pipe=Pipeline([\n",
    "    ('pre',pre),\n",
    "    ('xgb',xgb)\n",
    "])\n",
    "\n",
    "scores_pr = cross_val_score(pipe, X, y, scoring='average_precision', cv=gcv, n_jobs=-1, groups=groups)\n",
    "scores_roc = cross_val_score(pipe, X, y, scoring='roc_auc', cv=gcv, n_jobs=-1, groups=groups)\n",
    "\n",
    "print(\"PR-AUC:\", scores_pr.mean(), scores_pr)\n",
    "print(\"ROC-AUC:\", scores_roc.mean(), scores_roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da009af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F2-score: 0.4746163002802037 [0.4330814  0.46139111 0.46241396 0.4995423  0.51665273]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer, fbeta_score\n",
    "\n",
    "f2_scorer = make_scorer(fbeta_score, beta=2)\n",
    "\n",
    "scores_f2 = cross_val_score(pipe, X, y, scoring=f2_scorer, cv=gcv, groups=groups, n_jobs=-1)\n",
    "print(\"F2-score:\", scores_f2.mean(), scores_f2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e229aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PR-AUC: 0.8333486352603604 [0.81123381 0.84078191 0.84101291 0.82722396 0.84649059]\n",
      "F2-score: 0.6335824382253682 [0.59579762 0.61856577 0.62534309 0.6456444  0.68256131]\n"
     ]
    }
   ],
   "source": [
    "from time_transformer_tools import TimeFeaturesTransformer\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "\n",
    "tf = TimeFeaturesTransformer(\n",
    "    datetime_col=\"trans_date_trans_time\",\n",
    "    group_cols=(\"cc_num\",),\n",
    "    one_hot=True,\n",
    "    fill_first_delta=0,\n",
    "    drop_datetime=False\n",
    ")\n",
    "\n",
    "# 1) 明確把 tf 產生的數值特徵加到數值清單\n",
    "time_num_feats = [\"delta_sec_prev_tx\", \"is_unusual_hour\"]\n",
    "num_cols_final = num_cols + time_num_feats\n",
    "\n",
    "# 2) 針對四個 one-hot 欄位，直接 passthrough（它們已是 0/1，不要再經過 OneHotEncoder）\n",
    "bucket_selector = selector(pattern=r\"^time_bucket_\")  # 動態抓四欄\n",
    "\n",
    "pre = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "        ]), num_cols_final),\n",
    "\n",
    "        # 已經是 one-hot 的欄位直接通過\n",
    "        ('bucket_pass', 'passthrough', bucket_selector),\n",
    "\n",
    "        ('cat', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('ohe', OneHotEncoder(handle_unknown='ignore')),\n",
    "        ]), cat_cols),\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "pipe=Pipeline([\n",
    "    ('tf',tf),\n",
    "    ('pre',pre),\n",
    "    ('xgb',xgb)\n",
    "])\n",
    "\n",
    "scores_pr=cross_val_score(pipe,X,y,scoring='average_precision',cv=gcv,n_jobs=-1,groups=groups)\n",
    "print(\"PR-AUC:\",scores_pr.mean(),scores_pr)\n",
    "\n",
    "scores_f2 = cross_val_score(pipe, X, y, scoring=f2_scorer, cv=gcv, groups=groups, n_jobs=-1)\n",
    "print(\"F2-score:\", scores_f2.mean(), scores_f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c08f7f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'locat_transformer_tools' from 'c:\\\\Users\\\\USER\\\\Desktop\\\\資料分析\\\\作品\\\\信用卡交易詐欺偵測\\\\locat_transformer_tools.py'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import locat_transformer_tools\n",
    "reload(locat_transformer_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7423cbfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PR-AUC: 0.8444498497723737 [0.82381086 0.8521711  0.85077182 0.84291501 0.85258046]\n",
      "F2-score: 0.6867242150114028 [0.64971464 0.67524427 0.68792457 0.69564427 0.72509334]\n"
     ]
    }
   ],
   "source": [
    "from locat_transformer_tools import GeoTemporalFeatures\n",
    "\n",
    "geo = GeoTemporalFeatures(\n",
    "    lat_col=\"lat\", lon_col=\"long\",\n",
    "    merch_lat_col=\"merch_lat\", merch_lon_col=\"merch_long\",\n",
    "    city_col=\"city\", cc_col=\"cc_num\", time_col=\"trans_date_trans_time\",\n",
    "    merchant_key_cols=(\"merchant\"),\n",
    "    hours_window=24,\n",
    "    first_speed_fill=\"nan\",\n",
    "    return_dataframe=True,\n",
    "    append_original=True,          \n",
    "    drop_time_col_in_output=False \n",
    ")\n",
    "\n",
    "geo_cols = [\"distance_home_to_merchant\",\"travel_speed_kmh\",\"uniq_cities_24h\",\"uniq_merchants_24h\"]\n",
    "\n",
    "pre = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "        ]), num_cols_final),\n",
    "        ('bucket_pass', 'passthrough', bucket_selector),\n",
    "        (\"geo\", \"passthrough\", geo_cols),\n",
    "        ('cat', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('ohe', OneHotEncoder(handle_unknown='ignore')),\n",
    "        ]), cat_cols),\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "pipe=Pipeline([\n",
    "    ('tf',tf),\n",
    "    ('geo',geo),\n",
    "    ('pre',pre),\n",
    "    ('xgb',xgb)\n",
    "])\n",
    "\n",
    "scores_pr=cross_val_score(pipe,X,y,scoring='average_precision',cv=gcv,n_jobs=-1,groups=groups)\n",
    "print(\"PR-AUC:\",scores_pr.mean(),scores_pr)\n",
    "\n",
    "scores_f2 = cross_val_score(pipe, X, y, scoring=f2_scorer, cv=gcv, groups=groups, n_jobs=-1)\n",
    "print(\"F2-score:\", scores_f2.mean(), scores_f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "090ca0c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best PR-AUC: 0.8467928879219093\n",
      "Best params: {'xgb__colsample_bytree': np.float64(0.8537405378805455), 'xgb__gamma': np.float64(3.403527257773834), 'xgb__learning_rate': np.float64(0.09964018749757046), 'xgb__max_delta_step': 1, 'xgb__max_depth': 8, 'xgb__min_child_weight': 8, 'xgb__n_estimators': 446, 'xgb__reg_alpha': np.float64(0.000506930978634979), 'xgb__reg_lambda': np.float64(1.926898532522621), 'xgb__scale_pos_weight': 171, 'xgb__subsample': np.float64(0.6950550175969599), 'xgb__tree_method': 'hist'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer, precision_recall_curve\n",
    "from scipy.stats import randint, uniform, loguniform\n",
    "\n",
    "# ---- scorers ----\n",
    "def max_fbeta_from_proba(y_true, y_prob, beta=2.0):\n",
    "    p, r, thr = precision_recall_curve(y_true, y_prob)\n",
    "    f = (1+beta**2) * (p*r) / (beta**2 * p + r + 1e-12)\n",
    "    return np.nanmax(f[:-1])\n",
    "\n",
    "f2_scorer_prob = make_scorer(max_fbeta_from_proba, needs_threshold=True, greater_is_better=True)\n",
    "\n",
    "\n",
    "# ---- 覆蓋 xgb 參數空間 ----\n",
    "param_distributions = {\n",
    "    'xgb__n_estimators': randint(200, 1001),\n",
    "    'xgb__learning_rate': uniform(0.02, 0.15),      \n",
    "    'xgb__max_depth': randint(3, 9),\n",
    "    'xgb__min_child_weight': randint(1, 9),\n",
    "    'xgb__subsample': uniform(0.6, 0.4),            \n",
    "    'xgb__colsample_bytree': uniform(0.6, 0.4),    \n",
    "    'xgb__gamma': uniform(0.0, 5.0),\n",
    "    'xgb__reg_alpha': loguniform(1e-8, 1e-1),\n",
    "    'xgb__reg_lambda': loguniform(1e-2, 10), \n",
    "    'xgb__scale_pos_weight': [171],  \n",
    "    'xgb__tree_method': ['hist'],\n",
    "    'xgb__max_delta_step': randint(0, 5),\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=30,                        \n",
    "    scoring={'pr_auc': 'average_precision', 'f2': f2_scorer_prob},\n",
    "    refit='pr_auc',                    # 以 PR-AUC 為最終挑選\n",
    "    cv=gcv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "search.fit(X, y, groups=groups)\n",
    "print(\"Best PR-AUC:\", search.best_score_)\n",
    "print(\"Best params:\", search.best_params_)\n",
    "\n",
    "best_model = search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c026b252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "各 split 欄位 NaN 比例：\n",
      "split0_test_pr_auc    0.0\n",
      "split1_test_pr_auc    0.0\n",
      "split2_test_pr_auc    0.0\n",
      "split3_test_pr_auc    0.0\n",
      "split4_test_pr_auc    0.0\n",
      "dtype: float64\n",
      "best params 有效折數： 5 / 5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "res = pd.DataFrame(search.cv_results_)\n",
    "\n",
    "# 找出所有 split fold 的測試分數欄位\n",
    "fold_cols = [c for c in res.columns if c.startswith('split') and c.endswith('_test_pr_auc')]\n",
    "\n",
    "# 轉成 float 再檢查 NaN\n",
    "res[fold_cols] = res[fold_cols].astype(float)\n",
    "\n",
    "print(\"各 split 欄位 NaN 比例：\")\n",
    "print(res[fold_cols].isna().mean())\n",
    "\n",
    "# 檢查 best params 用到多少有效折\n",
    "best = res.loc[res['rank_test_pr_auc'].idxmin()]\n",
    "valid_folds = np.isfinite(best[fold_cols].astype(float)).sum()\n",
    "print(\"best params 有效折數：\", valid_folds, \"/\", len(fold_cols))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c30ccdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold (Max-F2): 0.9362, F2=0.9605\n",
      "Recall@P≥0.90: 0.9376 at threshold=0.9701\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['fraud_xgb_artifact.pkl']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import joblib\n",
    "\n",
    "best_model = search.best_estimator_   # 已用 best params refit 完成\n",
    "proba = best_model.predict_proba(X)[:,1]\n",
    "\n",
    "p, r, thr = precision_recall_curve(y, proba)\n",
    "\n",
    "# --- Max-F2 ---\n",
    "f2 = (5 * p * r) / (4 * p + r + 1e-12)\n",
    "best_idx = np.nanargmax(f2[:-1])  # 最後一點沒有對應 threshold\n",
    "best_th = float(thr[best_idx])\n",
    "best_f2 = float(f2[best_idx])\n",
    "print(f\"Best threshold (Max-F2): {best_th:.4f}, F2={best_f2:.4f}\")\n",
    "\n",
    "# --- Recall@P≥0.90 ---\n",
    "mask = p[:-1] >= 0.90   # precision 和 threshold 對齊\n",
    "if mask.any():\n",
    "    recall_at_p90 = float(r[:-1][mask].max())\n",
    "    th_at_p90 = float(thr[mask][r[:-1][mask].argmax()])\n",
    "else:\n",
    "    recall_at_p90, th_at_p90 = 0.0, 0.5\n",
    "\n",
    "print(f\"Recall@P≥0.90: {recall_at_p90:.4f} at threshold={th_at_p90:.4f}\")\n",
    "\n",
    "\n",
    "# 3) 持久化\n",
    "artifact = {\"model\": best_model, \"threshold\": best_th, \"metrics\": {\n",
    "    \"cv_pr_auc\": search.best_score_,\n",
    "    \"cv_f2_max\": best_f2,\n",
    "    \"recall_at_p90\": recall_at_p90\n",
    "}}\n",
    "joblib.dump(artifact, \"fraud_xgb_artifact.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57e321c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF PR-AUC=0.8477, OOF F2=0.7642\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score, fbeta_score, precision_recall_curve\n",
    "import numpy as np\n",
    "\n",
    "oof_proba = np.zeros_like(y, dtype=float)\n",
    "\n",
    "for tr, te in gcv.split(X, y, groups):\n",
    "    m = search.best_estimator_  \n",
    "    m.fit(X.iloc[tr], y[tr])\n",
    "    oof_proba[te] = m.predict_proba(X.iloc[te])[:,1]\n",
    "\n",
    "# 固定剛剛找到的門檻\n",
    "best_th = artifact['threshold'] if isinstance(artifact, dict) else best_th\n",
    "\n",
    "oof_pred = (oof_proba >= best_th).astype(int)\n",
    "p, r, _ = precision_recall_curve(y, oof_proba)\n",
    "pr_auc_oof = average_precision_score(y, oof_proba)\n",
    "f2_oof = fbeta_score(y, oof_pred, beta=2)\n",
    "\n",
    "print(f\"OOF PR-AUC={pr_auc_oof:.4f}, OOF F2={f2_oof:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869e7c76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
